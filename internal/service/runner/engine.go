package runner

import (
	"context"
	"fmt"
	"time"

	"example.com/agent-server/internal/service/llm"
	"example.com/agent-server/internal/store"
)

// AgentEngine è´Ÿè´£ç¼–æ’ä¸€æ¬¡ Run çš„å…¨è¿‡ç¨‹
type AgentEngine struct {
	Store     *store.MemoryStore
	LLMClient *llm.Client
}

func NewEngine(s *store.MemoryStore) *AgentEngine {
	cfg := llm.LLMConfig{
		ApiKey:      "apikey", //åç»­å¡«å…¥çœŸå®
		BaseURL:     "https://api.siliconflow.cn/v1",
		ModelName:   "Qwen2.5-VL-32B-Instruct",
		Temperature: 0.5,
	}
	return &AgentEngine{Store: s, LLMClient: llm.NewClient(cfg)}

}

// ExecuteRun æ ¸å¿ƒæ–¹æ³•ï¼šæ‰§è¡Œ Agent çš„æ€è€ƒå¾ªç¯
// è¿™é‡Œæ›¿æ¢æ‰ä¹‹å‰ handler é‡Œçš„ simulateAgentExecution
func (e *AgentEngine) ExecuteRun(ctx context.Context, runID string) (string, error) {

	run := e.Store.GetRun(runID) // æ ¹æ® runID è·å– run
	if run == nil {
		return "", fmt.Errorf("run not found")
	}
	session := e.Store.GetChatSession(run.SessionID) // è·å– run æ‰€åœ¨çš„ session
	if session == nil {
		return "", fmt.Errorf("session not found")
	}
	dbMsgs := e.Store.ListChatMessagesBySession(run.SessionID)
	history := DBMessageToOpenAI(dbMsgs)

	resp, err := e.LLMClient.ChatCompletion(ctx, llm.ChatRequest{
		SystemPrompt: "you are a devops assistant",
		History:      history,
		Tools:        nil, //å…ˆç½®ç©º
	})
	if err != nil {
		return "", err
	}

	if len(resp.ToolCalls) > 0 {
		// =======================================================
		// ğŸš€ The ReAct Loop (æ ¸å¿ƒå¾ªç¯)
		// =======================================================
		// ä¸ºäº†é˜²æ­¢æ­»å¾ªç¯ï¼Œè®¾ç½®æœ€å¤§æ­¥æ•°ï¼Œæ¯”å¦‚ 10 æ­¥
		maxSteps := 10

		for i := 0; i < maxSteps; i++ {
			// Step A: æ€è€ƒ (Call LLM)
			// llmResp, err := e.LLMClient.ChatCompletion(prompt)
			// ---------------------------------------------------
			// ã€æ¨¡æ‹Ÿ LLM è¿”å›ã€‘: å‡è®¾ç¬¬ä¸€æ¬¡è¿”å› ToolCallï¼Œç¬¬äºŒæ¬¡è¿”å›æ–‡æœ¬
			var llmDecision string
			if i == 0 {
				llmDecision = "TOOL_CALL: git_status" // æ¨¡æ‹Ÿæƒ³è°ƒå·¥å…·
			} else {
				llmDecision = "FINAL_ANSWER: ä»“åº“å¾ˆå¹²å‡€" // æ¨¡æ‹Ÿæœ€ç»ˆå›å¤
			}
			// ---------------------------------------------------

			// Step B: å¤„ç†å†³ç­–
			if isFinalAnswer(llmDecision) {
				// 1. è®°å½• Assistant æ¶ˆæ¯
				e.saveMessage(run, "assistant", "ä»“åº“å¾ˆå¹²å‡€", "")
				return "ä»“åº“å¾ˆå¹²å‡€", nil
			}

			if isToolCall(llmDecision) {
				// 1. è®°å½• "æˆ‘è¦è°ƒå·¥å…·" çš„æƒ³æ³•
				e.saveMessage(run, "assistant", "æ­£åœ¨æ£€æŸ¥çŠ¶æ€...", "call_id_123")

				// 2. è®°å½• RunStep (Tool Start)
				e.saveStep(run, "tool_start", "git_status", nil)

				// Step C: è¡ŒåŠ¨ (Execute Tool)
				// toolResult := e.executeTool("git_status", args)
				toolResult := "On branch main, nothing to commit" // æ¨¡æ‹Ÿç»“æœ

				// 3. è®°å½• RunStep (Tool End)
				e.saveStep(run, "tool_end", "git_status", map[string]interface{}{"output": toolResult})

				// 4. è®°å½• Tool Message (è§‚å¯Ÿ)
				// è¿™ä¸€æ­¥éå¸¸é‡è¦ï¼æŠŠç»“æœå–‚å›ç»™ LLM
				e.saveMessage(run, "tool", toolResult, "call_id_123")

				// Continue Loop -> LLM çœ‹åˆ°ç»“æœåï¼Œè¿›å…¥ä¸‹ä¸€æ¬¡è¿­ä»£
			}
		}
	}

	return "", fmt.Errorf("max steps reached")
}

// è¾…åŠ©å‡½æ•°ï¼šå­˜æ¶ˆæ¯
func (e *AgentEngine) saveMessage(run *store.Run, role, content, toolCallID string) {
	e.Store.CreateChatMessage(&store.ChatMessage{
		SessionID:  run.SessionID,
		RunID:      run.ID,
		Role:       role,
		Content:    map[string]interface{}{"type": "text", "text": content},
		ToolCallID: toolCallID,
		CreatedAt:  time.Now(),
	})
}

// è¾…åŠ©å‡½æ•°ï¼šå­˜æ­¥éª¤
func (e *AgentEngine) saveStep(run *store.Run, stepType, name string, payload map[string]interface{}) {
	e.Store.CreateRunStep(&store.RunStep{
		RunID:         run.ID,
		StepType:      stepType,
		Name:          name,
		OutputPayload: payload,
		StartedAt:     time.Now(),
	})
}

// ç®€å•çš„ Mock åˆ¤æ–­é€»è¾‘
func isFinalAnswer(s string) bool { return len(s) > 12 } // ç®€å•æ¨¡æ‹Ÿ
func isToolCall(s string) bool    { return s == "TOOL_CALL: git_status" }
